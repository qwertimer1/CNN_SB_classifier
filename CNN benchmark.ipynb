{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CNN benchmark tool kit for Whale detection\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook contains the architecture design for the classification of Whale species based on their chirp patterns. The classification task takes in a series of Whale speech patterns collected from a variety of locations around the world and cleaned and collated thanks to impart the work done by MobySound. ()\n",
    "\n",
    "Further data cleaning and tidying up has been undertakne on my part to help make the dataset useable for RNNs and this CNN benchmark. The initial approach in this classification task is to take a series of pretrained architectures including inception, resnet and Densenet and implement transfer learning whereby the last layers of the pretrained network is removed and the new dataset outputs are placed on top. \n",
    "\n",
    "This means that rather than looking at the original outpur classification layer of x number of classes. The network sees the classes related to our dataset. The first task is to do a simple retraining of the last layers of the network using a fixed learning rate of 1e-3 or similar and compare the results across the architectural designs. Following this approach The networks will be partially retrained using varaible learning weights accross the layers. This approach is implemented using the fastai library developed by Jeremy Howard et al[]. \n",
    "\n",
    "This libary includes a learning rate finder which can optimally find the learning rate for our last layers of the network. This approach will help to validate the previous work to show that transfer learning performs quite well on this dataset. The final approach in this benchmark will be to retrain the networks from scratch. The thoughts on this are that the network will perform better with the pretrained network rather than on the fully trained network."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Torch Imports\n",
    "\n",
    "import torch\n",
    "import torch.utils.data\n",
    "from torch.utils.data import Dataset, TensorDataset, DataLoader #as DataLoaderBase\n",
    "from torch import nn, optim, sigmoid\n",
    "from torch.nn import functional as F\n",
    "from torchvision import datasets, transforms\n",
    "from torch.nn import modules\n",
    "from torch.nn.modules import loss\n",
    "from torch.autograd import Variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#System imports\n",
    "\n",
    "import os\n",
    "import sys\n",
    "import shutil\n",
    "from glob import glob\n",
    "import datetime\n",
    "import re\n",
    "from tqdm import tqdm\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from PIL import Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'config_file.json'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-4-78813d096840>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 7\u001b[1;33m \u001b[1;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'config_file.json'\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      8\u001b[0m     \u001b[0mdata\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mjson\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mload\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mf\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      9\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'config_file.json'"
     ]
    }
   ],
   "source": [
    "#Importing and viewing config file\n",
    "\n",
    "import json\n",
    "from pprint import pprint\n",
    "\n",
    "\n",
    "with open('config_file.json') as f:\n",
    "    data = json.load(f)\n",
    "\n",
    "pprint(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "class image_dataset(Dataset):\n",
    "    def __init__(self, data_dir, img_path, img_filename, label_filename,exp_phase = \"train\", transform=None):\n",
    "        self.data_dir = data_dir\n",
    "        self.transform = transform\n",
    "        self.testing_percentage = testing_percentage\n",
    "        self.validation_percentage = validation_percentage\n",
    "        self.exp_phase = exp_phase\n",
    "        # reading img file from file\n",
    "        self.results = create_image_lists()\n",
    "        convert_for_pytorch()\n",
    "        self.label = labels\n",
    "        \n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        \n",
    "        img = Image.open(os.path.join(self.data_dir, self.results[''][self.exp_phase]))\n",
    "        \n",
    "        \n",
    "        img = img.convert('RGB')\n",
    "        if self.transform is not None:\n",
    "            img = self.transform(img)\n",
    "        label = torch.from_numpy(self.label[index])\n",
    "        return img, label\n",
    "                         \n",
    "    def __len__(self):\n",
    "        return len(self.img_filename)\n",
    "                           \n",
    "    def convert_for_pytorch(self):\n",
    "        images = []\n",
    "        for sub_dirs in self.sub_dirs:\n",
    "            self.images.append(results[sub_dir][self.exp_phase])\n",
    "                         \n",
    "            \n",
    "        \n",
    "       \n",
    "    def create_image_lists(self):\n",
    "        MAX_NUM_IMAGES_PER_CLASS = 2 ** 27 -1\n",
    "\n",
    "        as_bytes = util.as_bytes()\n",
    "                             \n",
    "        if not os.path.exists(self.data_dir):\n",
    "            print(\"error\")\n",
    "            return None\n",
    "        result = {}\n",
    "        self.sub_dirs = [x[0] for x in os.walk(self.data_dir)]\n",
    "        print(self.sub_dirs)\n",
    "        is_root_dir = True\n",
    "        for sub_dir in self.sub_dirs:\n",
    "            if is_root_dir:\n",
    "                is_root_dir = False\n",
    "                continue\n",
    "            extensions = ['jpg', 'jpeg', 'JPG', 'JPEG']\n",
    "            file_list = []\n",
    "            dir_name = os.path.basename(sub_dir)\n",
    "            if dir_name == self.data_dir:\n",
    "                continue\n",
    "            for extension in extensions:\n",
    "                file_glob = os.path.join(self.data_dir, dir_name, '*' + extension)\n",
    "                file_list.extend(glob.glob(file_glob))\n",
    "            if not file_list:\n",
    "                print(\"No files found\")\n",
    "                continue\n",
    "            if len(file_list) < 20:\n",
    "                print(\"folder has less than 20 images, this may cause issues\")\n",
    "            if len(file_list) > MAX_NUM_IMAGES_PER_CLASS:\n",
    "                print(\"folder has too many images\")\n",
    "            self.label_name = re.sub(r'[^a-z0-9]+', ' ', dir_name.lower())\n",
    "            training_images = []\n",
    "            testing_images = []\n",
    "            validation_images = []\n",
    "            for file_name in file_list:\n",
    "                base_name = os.path.basename(file_name)\n",
    "                hash_name = re.sub(r'_nohash_.*$', '', file_name)\n",
    "                hash_name_hashed = hashlib.sha1(as_bytes(hash_name)).hexdigest()\n",
    "                percentage_hash = ((int(hash_name_hashed, 16) %\n",
    "                                    (MAX_NUM_IMAGES_PER_CLASS + 1)) *\n",
    "                                   (100.0 / MAX_NUM_IMAGES_PER_CLASS))\n",
    "                if percentage_hash < self.validation_percentage:\n",
    "                    self.validation_images.append(base_name)\n",
    "                elif percentage_hash < (self.testing_percentage + self.validation_percentage):\n",
    "                    self.testing_images.append(base_name)\n",
    "                else:\n",
    "                    self.training_images.append(base_name)\n",
    "                result[self.label_name] = {\n",
    "                    'dir': dir_name,\n",
    "                    'training': self.training_images,\n",
    "                    'testing': self.testing_images,\n",
    "                    'validation': self.validation_images,\n",
    "                }\n",
    "        return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "unexpected EOF while parsing (<ipython-input-6-b12c2d29af3c>, line 1)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;36m  File \u001b[1;32m\"<ipython-input-6-b12c2d29af3c>\"\u001b[1;36m, line \u001b[1;32m1\u001b[0m\n\u001b[1;33m    class preprocessing():\u001b[0m\n\u001b[1;37m                          ^\u001b[0m\n\u001b[1;31mSyntaxError\u001b[0m\u001b[1;31m:\u001b[0m unexpected EOF while parsing\n"
     ]
    }
   ],
   "source": [
    "class preprocessing():"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
